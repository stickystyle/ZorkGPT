[project]
name = "ZorkGPT"
version = "0.1.0"
description = "Teaching AI to play the classic text adventure Zork using Large Language Models"
requires-python = ">=3.11"
dependencies = [
    "openai>=1.79.0",
    "pydantic>=2.11.4",
    "requests>=2.31.0",
    "python-dotenv>=1.0.0",
    "jericho>=3.3.0",
    # needed for Jericho get_valid_actions() call
    "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl",
    "langfuse>=3.8.1,<4.0",
    "filelock>=3.20.0",
]

[project.optional-dependencies]
test = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
]
s3 = [
    "boto3>=1.34.0",
]

[dependency-groups]
dev = [
    "pytest>=8.3.5",
]

[tool.zorkgpt.llm]
# LLM Configuration
client_base_url = "https://openrouter.ai/api/v1"
agent_model = "deepseek/deepseek-r1-0528"
#info_ext_model = "gemma-3-12b-it-qat"
info_ext_model = "google/gemma-3-12b-it"
#critic_model = "gemma-3-12b-it-qat"
#critic_model = "google/gemma-3-12b-it"  # Too small - fails to follow movement validation logic
critic_model = "google/gemma-3-27b-it"   # Correctly validates movements against available exits
analysis_model = "deepseek/deepseek-r1-0528"  # Superior reasoning depth and actionable pattern extraction vs llama-4-scout
memory_model = "qwen/qwq-32b"
condensation_model = "qwen/qwq-32b"

# Per-model base URLs (optional, for cost optimization)
# If not specified, will fall back to client_base_url
# Examples:
# agent_base_url = "https://api.together.xyz/v1"
# info_ext_base_url = "http://oracle.nord:1234/v1"
# critic_base_url = "http://oracle.nord:1234/v1"
# analysis_base_url = "https://api.openai.com/v1"

[tool.zorkgpt.retry]
# Retry and Exponential Backoff Configuration
max_retries = 5
initial_delay = 1.0           # Initial retry delay in seconds
max_delay = 60.0              # Maximum retry delay in seconds
exponential_base = 2.0        # Multiplier for exponential backoff
jitter_factor = 0.1           # Random jitter to prevent thundering herd (0.0 to 1.0)
retry_on_timeout = true
retry_on_rate_limit = true
retry_on_server_error = true  # 5xx errors
timeout_seconds = 120.0
# Circuit breaker settings
circuit_breaker_enabled = true
circuit_breaker_failure_threshold = 10    # Number of failures before opening circuit
circuit_breaker_recovery_timeout = 300.0  # Seconds before trying to close circuit
circuit_breaker_success_threshold = 3     # Consecutive successes needed to close circuit

[tool.zorkgpt.agent_sampling]
# Agent LLM Sampling Parameters, taken from Qwen model card
temperature = 0.6
top_p = 0.95
top_k = 20
min_p = 0.0
# max_tokens = null  # Optional - leave commented to use default

[tool.zorkgpt.critic_sampling]
# Critic LLM Sampling Parameters
temperature = 0.1  # Low temperature for consistent validation logic
max_tokens = 100
# top_p = null     # Optional - leave commented for default
# top_k = null     # Optional - leave commented for default
# min_p = null     # Optional - leave commented for default

[tool.zorkgpt.extractor_sampling]
# Information Extractor LLM Sampling Parameters
temperature = 0.1
max_tokens = 400
# top_p = null     # Optional - leave commented for default
# top_k = null     # Optional - leave commented for default
# min_p = null     # Optional - leave commented for default

[tool.zorkgpt.memory_sampling]
# Memory Synthesis LLM Sampling Parameters
temperature = 0.3
max_tokens = 1000
# top_p = null     # Optional - leave commented for default
# top_k = null     # Optional - leave commented for default
# min_p = null     # Optional - leave commented for default

[tool.zorkgpt.analysis_sampling]
# Analysis Model LLM Sampling Parameters (for knowledge generation)
temperature = 0.3
top_p = 0.8     # Optional - leave commented for default
top_k = 20     # Optional - leave commented for default
min_p = 0.0     # Optional - leave commented for default
max_tokens = 5000  # Optional - leave commented to use default

[tool.zorkgpt.condensation_sampling]
# Knowledge Condensation LLM Sampling Parameters
temperature = 0.3
top_p = 0.8
top_k = 20
min_p = 0.0
max_tokens = 5000

[tool.zorkgpt.gameplay]
# Gameplay Configuration
turn_delay_seconds = 3.0
turn_window_size = 100
min_knowledge_quality = 6.0
critic_rejection_threshold = -0.2  # More permissive from -0.05 to allow more experimentation
# Exit pruning configuration
enable_exit_pruning = true
exit_failure_threshold = 2  # Reduced from 3 to more quickly abandon failed directions
# Knowledge base condensation configuration  
enable_knowledge_condensation = true
knowledge_condensation_threshold = 15000  # Characters before triggering condensation
# Save/restore configuration
zork_save_filename_template = "zorkgpt_save_{timestamp}"
zork_game_workdir = "game_files"

[tool.zorkgpt.orchestrator]
# Orchestrator Configuration
max_turns_per_episode = 5000
knowledge_update_interval = 100
objective_update_interval = 25
enable_state_export = true
max_context_tokens = 40000
context_overflow_threshold = 0.6

enable_objective_refinement = true
objective_refinement_interval = 50
max_objectives_before_forced_refinement = 15
refined_objectives_target_count = 8

# Inter-episode synthesis configuration
enable_inter_episode_synthesis = true
# Legacy: kept for migration purposes only - cross-episode insights now in knowledgebase.md
persistent_wisdom_file = "persistent_wisdom.md"

[tool.zorkgpt.simple_memory]
# Simple Memory System Configuration
memory_file = "Memories.md"
max_memories_shown = 10

[tool.zorkgpt.files]
# File Configuration
episode_log_file = "zork_episode_log.txt"
json_log_file = "zork_episode_log.jsonl"
state_export_file = "current_state.json"
map_state_file = "map_state.json"
game_file_path = "jericho-game-suite/zork1.z5"

[tool.zorkgpt.aws]
# AWS Configuration (optional)
s3_key_prefix = "zorkgpt/"

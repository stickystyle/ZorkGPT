# =============================================================================
# ZorkGPT Environment Configuration Example
# =============================================================================
# Copy this file to .env and fill in your actual credentials
# DO NOT commit .env to version control - it contains secrets!

# -----------------------------------------------------------------------------
# LLM Provider API Keys
# -----------------------------------------------------------------------------
# OpenAI API key (if using OpenAI models directly)
# OPENAI_API_KEY=sk-proj-your-openai-key-here

# DeepSeek API key (if using DeepSeek models)
# DEEP_SEEK=sk-your-deepseek-key-here

# OpenRouter API key (default provider for multi-model access)
# OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key-here

# Generic client API key (used by llm_client.py)
# Set this to your active provider's API key
#
# BACKWARD COMPATIBILITY:
#   - CLIENT_API_KEY (legacy, still supported)
#   - ZORKGPT_CLIENT_API_KEY (new, recommended)
# Both work, but ZORKGPT_CLIENT_API_KEY takes precedence if both are set
CLIENT_API_KEY=sk-or-v1-your-api-key-here
# ZORKGPT_CLIENT_API_KEY=sk-or-v1-your-api-key-here

# Optional: Override the LLM client base URL
# Default is set in pyproject.toml [tool.zorkgpt.llm]
# CLIENT_BASE_URL=https://openrouter.ai/api/v1

# -----------------------------------------------------------------------------
# Langfuse Observability (LLM Tracing and Analytics)
# -----------------------------------------------------------------------------
# Langfuse provides comprehensive observability for all LLM calls in ZorkGPT
#
# Architecture Mapping:
#   - Session ID = Episode ID (one per game episode)
#   - Trace ID = Turn ID (one per game turn)
#   - Spans = Individual LLM calls within a turn
#
# All 4 LLM components are traced:
#   1. Agent - Action generation
#   2. Critic - Action evaluation
#   3. Extractor - Information extraction
#   4. Strategy Generator - Knowledge synthesis
#
# Graceful Degradation:
#   - Leave LANGFUSE_PUBLIC_KEY empty ("") to disable Langfuse integration
#   - System will continue to operate normally without tracing
#
# Sign up at https://cloud.langfuse.com to get your keys

# Langfuse public key (safe to use in frontend/client code)
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key-here

# Langfuse secret key (NEVER expose this in client code or version control)
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key-here

# Langfuse host (use cloud.langfuse.com for managed service)
LANGFUSE_HOST=https://cloud.langfuse.com

# -----------------------------------------------------------------------------
# Game Configuration Overrides
# -----------------------------------------------------------------------------
# Maximum turns per episode (can override pyproject.toml setting)
MAX_TURNS_PER_EPISODE=200

# -----------------------------------------------------------------------------
# AWS S3 Configuration (for state export)
# -----------------------------------------------------------------------------
# S3 bucket for exporting game state and logs
#
# BACKWARD COMPATIBILITY:
#   - ZORK_S3_BUCKET (legacy, still supported)
#   - ZORKGPT_S3_BUCKET (new, recommended)
# Both work, but ZORKGPT_S3_BUCKET takes precedence if both are set
# ZORK_S3_BUCKET=your-s3-bucket-name
# ZORKGPT_S3_BUCKET=your-s3-bucket-name

# -----------------------------------------------------------------------------
# Model Selection Overrides (Optional)
# -----------------------------------------------------------------------------
# Uncomment to override model selections from pyproject.toml
# AGENT_MODEL=openai/gpt-4o-mini
# CRITIC_MODEL=google/gemini-2.0-flash-001
# INFO_EXT_MODEL=google/gemini-2.0-flash-001
# ANALYSIS_MODEL=openai/gpt-4.1-nano
